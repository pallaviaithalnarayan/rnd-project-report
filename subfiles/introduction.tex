%!TEX root = ../report.tex
\documentclass[../report.tex]{subfiles}

\begin{document}
    \section{Introduction}
    \label{sec:introduction}
    % what background the reader needs? What is the hypothesis?
    % Compared to traditional way of generating the ground truths for semantic segmentation, we use airsim which is developed by Microsoft is one of the modern approach of generating different types of data to be used for AI research to experiment with deep learning, computer vision and reinforcement learning algorithms for autonomous vehicles. 
    % In this paper, we focus mainly on generating the semantic segmentation along with images from the scene, whereas using the airsim plugin we can also obtain bounding boxes for object detection, depth for depth estimation, etc. 

    % From the cityscapes paper, we see that to generate a single segmentation of an image took approximately 2.5 hours, which needs more time and resource for data collection. Our approach is to collect data with less time and effort with synthetic data generation. There is a room for open research to understand if using synthetic data improves the machine learning models? if it improves, how well can it perform testing with real data? These are the questions that are focused on in this paper. There is existing research in the ground perspective, so we are focusing on the aerial perspective to cover the aerial applications. 

    % When we do supervised learning, the model depends totally on the data with fine ground truth. When human labels the data there are chances of mistakes compared to our approach as obsereved these human errors can be managed well since no manual segmentation is required. The objects from the scene get segmented based on it's assigned segmentation object id. 

    % We can also observe how varying certain parameters with data generation will change the model's performance for example: different heights, weather, environments, number of data, etc. 
    
    % With this brief introduction one gets to understand how the modern approaches are helping researchers to focus more on generating their own datasets instead of training the models without the knowledge of what data they are using. 
    
    
    % With the development of artificial intelligence, machines can distinguish between different classes of objects and background areas in images by using semantic segmentation tasks. For models to learn how to recognize the context in digital images which can include people, landscapes, medical images, and much more semantic segmentation has emerged as a vital technique. The primary aim is to explore the feasibility of utilizing synthetic data, this includes a comparative assessment of segmentation models.Though numerous datasets are available for more intricate computer vision applications, datasets from the aerial perspective are lacking to train machine learning algorithms. 

    Semantic segmentation, also called content-based image segmentation, is a computer vision task that helps understand the scene or the context of an image by classifying each pixel into a semantic class. Semantic segmentation is used in various fields such as medicine, robotics, autonomous driving, etc. Segmentation tasks are solved in a supervised learning fashion, by relying on a dataset of images annotated at pixel level, and training with them a machine learning model \cite{csurka2022semantic}. 
    
    For supervised learning, one would require an enormous amount of training samples to make it learn useful features. Without well-defined ground truths, it is a tedious process of training any supervised tasks. Annotation is time-consuming and expensive. For example, annotating a single image in the Cityscapes dataset took an average of over 1.5 hours \cite{cordts2016cityscapes}. This paves the way to the use of synthetic data generation. 
    
    While numerous datasets exist for ground-level semantic segmentation in autonomous driving applications, aerial perspective datasets remain limited.
    Given this limitation in aerial datasets, this research project aims to evaluate whether using synthetic data can improve the performance of existing segmentation models. Compared to the traditional methods of generating ground-truths for semantic segmentation, modern high-level graphics platforms like game engines (Unity, Unreal Engine) can be used to obtain various types of datasets (RGB images, depth, segmentation, etc.) tailored to specific research domains for training deep learning models.

    We use AirSim, an open-source framework developed by Microsoft Research, designed to provide a platform for experimenting with deep learning, computer vision, and reinforcement learning for autonomous vehicles \cite{shah2018airsim}.
    AirSim is used as an Unreal Engine (UE) plugin in realistic environments built with UE to generate synthetic semantic segmentation datasets. 
    We evaluate the synthetic data using 7 classes building, road, tree, vegetation, human, vehicle, and clutter by comparing it with existing real datasets to assess improvements in segmentation task from using artificial training data, with mean IoU and per-class IoU as evaluation metrics.
    
% ---------------------------------------------------------------------------

    \subsection{Motivation}
    \label{sec:introduction:motivation}
    % why should someone care?

    % Fraunhofer FKIE's aim in this R\&D project is to research in aerial applications using the segmentation models to understand if there are any hidden objects or threats in Miliray aeras.  
    % Also for scene understanding such as forest, urban land, agricultural land, etc. Detecting roads, buildings, vehicles, parking lots, construction sites for traffic management, urban planning, timely scene comparision

    % If the synthetic data improves the model along with real data. There will be less effort required to collect the real data and try to replicate the same number of classes with varying environments in the synthetic data generation.
    % This helps the model learn better with synthetic data. Reducing the man power and various restrictions of collecting data in real-time. 

    % Synthetic data generation not only helps in aerial applications can also be used for various topics of interest. 

     % <-- Fraunhofer Institute for Communication, Information Processing and Ergonomics FKIE's aim in this R\&D project is to research in finding insights from any improvements in the semantic segmentation using synthetic data and apply it for aerial applications to understand if there are any hidden objects or threats in Military aeras.  --> 

    
    In this research and development project, the Fraunhofer Institute for Communication, Information Processing and Ergonomics FKIE's goal is to use synthetic data to extract insights from any advancements in synthetic semantic segmentation and use it for aerial applications to determine whether there are any threats in military areas. Additionally, this can be utilized for construction site detection, traffic control, urban planning, and rapid scene comparison.
    
        % <-- This can also  be used for scene understanding such as forest, urban land, agricultural land, etc. Detecting roads, buildings, vehicles, parking lots, construction sites for traffic management, urban planning, timely scene comparision.  --> 
    
    
    The present research intends to support the larger objective of reducing the dependence on costly manual annotation procedures while increasing the accessibility and usefulness of semantic segmentation for real-world applications by assessing the efficacy of synthetic training data. In order to overcome issues with data annotation burden, changing environmental conditions, quality assurance, domain adaptation, and cost efficiency, this study investigates the possibility of employing artificial data produced by the UE with the AirSim plugin.  

% ----------------------------------------------------------------------------

    \subsection{Problem Statement}
    \label{sec:introduction:problem_statement}
    % What to do?

    % Machine learning algorithms require large-scale, high-quality, and diversified training datasets for supervised learning techniques. As the existing researches are mainly focusing on ground perspective semantic segmentation for autonomous driving applications, we observed there is a keen research requirement in the aerial fields.  

    % Focusing the aerial semantic segmentation, the images are generated from aerial view with groundtruth for supervised training. 

    % This R\&D aims to evaluate semantic segmentation using synthetic data generated from Unreal game Engine with the help of Airsim.

    % Existing datasets and methodologies may not be sufficient for addressing aerial applications. 
    
    % The upcoming sections provide an in-depth overview of the state of the art, illustrating how different authors overcome these challenges through deep learning-based approaches for semantic segmentation. Furthermore, this paper will outline the proposed method, along with the evaluation of the models, conclusions, challenges faced, existing limitations, and future exploration.

    The laborious and costly manual annotation procedure makes it difficult to obtain large amounts of reliably labeled ground-truth data, even though deep learning-based semantic segmentation has shown good results in a variety of computer vision tasks \cite{cordts2016cityscapes}. Although creating synthetic data with UE presents a viable solution as we have limited understanding about how well models trained in synthetic data translate to real-world situations and what factors affect the transferability of learning from synthetic to real-world environments.  

    In order to determine the viability of synthetic data as a supplement or alternative, this R\&D examines how well deep learning models perform when trained using artificially generated semantic segmentation data from the UE, AirSim plugin and assesses how well they perform when applied to real-world images. The related work, methodology, evaluation, conclusion, and future work are presented in the upcoming sections.   
    % \textcolor{red}{hi}

\end{document}

For plural UAVs: glspl{}