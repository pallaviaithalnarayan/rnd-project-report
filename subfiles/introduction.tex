%!TEX root = ../report.tex
\documentclass[../report.tex]{subfiles}

% \begin{document}
%     \section{Introduction}
%     \label{sec:introduction}

%     This is a template for MAS R\&D projects, based on \emph{IEEETran}.
%     Here are some preliminaries about some common things you need to do to use the template:
%     \begin{itemize}
%         \item Add your references to the file \emph{references.bib} and cite them as Mustermann and Smith \cite{referenceexample} (if there are more than three authors, cite as Mustermann et al. \cite{referenceexample}).
%         \item Refer to sections as Sec. \ref{sec:introduction}.
%         \item You can include figures as follows (note that the figure caption is below the figure).
%         \begin{figure}[ht]
%             \centering
%             \includegraphics[width=0.8\linewidth]{figures/b-it-logo.pdf}
%             \caption{My caption}
%             \label{fig:figureexample}
%         \end{figure}
%         Refer to figures as Fig. \ref{fig:figureexample}.
%         \item You can add tables as follows (note that the table caption is above the table).
%         \begin{table}[ht]
%             \caption{My caption}
%             \label{tab:tableexample}
%             \begin{tabular}{M{0.45\linewidth} M{0.45\linewidth}}
%                 \hline
%                 \cellcolor{gray!10!white} Header 1 & \cellcolor{gray!10!white} Header 2 \\\hline
%                 Cell 1 & Cell 2 \\\hline
%                 Cell 3 & Cell 4 \\\hline
%             \end{tabular}
%         \end{table}
%         Refer to tables as Tab. \ref{tab:tableexample}.
%         \item You can add equations as follows.
%         \begin{equation}
%             f(x) = \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{1}{2}\left( \frac{x - \mu}{\sigma} \right)^2}
%             \label{eq:equationexample}
%         \end{equation}
%         Refer to equations as Eq. \ref{eq:equationexample}.
%     \end{itemize}

%     \subsection{Motivation}
%     \label{sec:introduction:motivation}

%     Describe the context of your work and the motivation for it.

%     \subsection{Problem Statement}
%     \label{sec:introduction:problem_statement}

%     Describe the problem you are addressing in the work.

%     \subsection{Proposed Approach}
%     \label{sec:introduction:proposed_approach}

%     Write a short summary of your proposed approach.

% \end{document}

\begin{document}
    \section{Introduction}
    \label{sec:introduction}
    % what background the reader needs? What is the hypothesis?
    Semantic segmentation plays an important role in understanding the scenes or context of the images. It is referred to as content-based image segmentation and it is a computer vision problem where the task is to determine to which semantic class each pixel of an image belongs. Typically, this problem is approached in a supervised learning fashion, by relying on a dataset of images annotated at pixel level, and training with them a machine learning model to perform the task \cite{csurka2022semantic}. 
    
    Semantic segmentation is used in various fields such as medicine, robotics, autonomous driving, etc. For supervised learning, one would require an enormous amount of training samples to make it learn useful knowledge; without well-defined ground truths, it is a tedious process of training any supervised tasks. Annotation is time-consuming and expensive. For example, annotating the Cityscapes dataset took more than 1.5 hours on average for a single image \cite{cordts2016cityscapes}. This opens the door to the use of synthetic data generation. 
    
    Currently there are many openly available datasets for semantic segmentation in the ground perspective for autonomous driving applications compared to aerial perspective. In the case of our proposed supervised approach, we are aiming to evaluate if using synthetic data can improve the performance using existing segmentation models. Compared to the traditional way of generating the ground-truths for semantic segmentation, modern high-level graphics platforms such as game engines (Unity, Unreal) can be used to obtain different kinds of datasets(RGB images, depth, segmentation, etc) based on their research domain to train deep learning models.
    
    We use AirSim, an open-source framework developed by the Microsoft Research Group with the aim of providing a platform to experiment with deep learning, computer vision and reinforcement learning for autonomous vehicles. \cite{shah2018airsim}.
    AirSim is used as an Unreal plugin in realistic environments built with Unreal Engine to generate synthetic semantic segmentation datasets. Using 7 classes such as building, road, tree, vegetation, human, vehicle, and clutter we evaluate the synthetic data with the existing real datasets to see for improvements in using artificial training data with mean IoU and per class IoU as evaluation metrics.  
    
    With this brief introduction one gets to understand how the modern approaches are helping researchers to focus more on generating their own datasets instead of training the models without the knowledge of what data they are using. The primary aim is to explore the feasibility of utilizing synthetic data, including a comparative assessment of segmentation models.
% ---------------------------------------------------------------------------

    \subsection{Motivation}
    \label{sec:introduction:motivation}
    % why should someone care?

    In this research and development project, the Fraunhofer Institute for Communication, Information Processing and Ergonomics FKIE's goal is to use synthetic data to extract insights from any advancements in synthetic semantic segmentation and use it for aerial applications to determine whether there are any threats in military areas. Additionally, this can be utilized to comprehend scenes such as forests, cities, farms, et cetera. Road, building, car, parking lot and construction site detection for traffic control, urban planning, and rapid scene comparison.
    
        % <-- This can also  be used for scene understanding such as forest, urban land, agricultural land, etc. Detecting roads, buildings, vehicles, parking lots, construction sites for traffic management, urban planning, timely scene comparision.  --> 
    
    
    The present research intends to support the larger objective of reducing the dependence on costly manual annotation procedures while increasing the accessibility and usefulness of semantic segmentation for real-world applications by assessing the efficacy of synthetic training data. In order to overcome issues with data annotation burden, changing environmental conditions, quality assurance, domain adaptation, and cost efficiency, this study investigates the possibility of employing artificial data produced by the Unreal Engine with the AirSim plugin.  
    
% ----------------------------------------------------------------------------

    \subsection{Problem Statement}
    \label{sec:introduction:problem_statement}
    % What to do?

    The laborious and costly manual annotation procedure makes it difficult to obtain large amounts of reliably labeled ground-truth data, even though deep learning-based semantic segmentation has shown good results in a variety of computer vision tasks \cite{cordts2016cityscapes}. Although creating synthetic data with programs like AirSim and Unreal Engine presents a viable solution, we have limited understanding about how well models trained in synthetic data translate to real-world situations and what factors affect the transferability of learning from synthetic to real-world environments.  

    In order to determine the viability of synthetic data as a supplement or alternative, this R\&D examines how well deep learning models perform when trained using artificially generated semantic segmentation data from the Unreal Engine framework, AirSim plugin and assesses how well they perform when applied to real-world images. 
    
    The upcoming sections provide an in-depth overview of the state of the art, illustrating how different authors overcome these challenges through deep learning-based approaches for semantic segmentation. The related work, methodology, evaluation, conclusion and future work are presented in the upcoming sections.   


\end{document}
